services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.16.0

    command: ["mlflow", "server", "-h", "0.0.0.0", "-p", "5000"]

    # exposing the port that will be used by MLFlow
    ports:
      - "5000:5000"

  # creating the application environment 
  app:
    image: e2e:latest

    build:
      context: .
      dockerfile: ./Dockerfile

    working_dir: /e2e-mlops-project/src/

    depends_on:
      - mlflow

    command: ["fastapi", "run", "api/main.py", "--host", "0.0.0.0", "--port", "8000"]

    # exposing the port that will be used by FastAPI
    ports:
      - "8000:8000"

    # setting external volumes
    volumes:
      - ./models:/e2e-mlops-project/models/
      - ./data:/e2e-mlops-project/data/
      - ./reports:/e2e-mlops-project/reports/
      - ./notebooks/VERSION:/e2e-mlops-project/notebooks/VERSION
